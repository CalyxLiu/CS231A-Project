{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLgdyo1jgQmk"
      },
      "source": [
        "Copyright 2020 Google LLC.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \\\"License\\\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2XCUxOexgRF7"
      },
      "outputs": [],
      "source": [
        "#@title License\n",
        "# Licensed under the Apache License, Version 2.0 (the \\\"License\\\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \\\"AS IS\\\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Impressionist Datasets\n",
        "\n",
        "## First, download it from Kaggle and upload it to Google drive. Then, load it using the cells below."
      ],
      "metadata": {
        "id": "7pKFByTUq671"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlVQwDymrDl0",
        "outputId": "01502af8-1efc-448e-9fce-8bff8a3fa598"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN8Ud050qB4p"
      },
      "source": [
        "# Single image to MPI example Colab\n",
        "\n",
        "This Colab is part of code for the paper ___Single-view view synthesis with multiplane images___, and may be found at <br>https://github.com/google-research/google-research/tree/master/single_view_mpi.\n",
        "\n",
        "The project site is at https://single-view-mpi.github.io/.\n",
        "\n",
        "Choose __Run all__ from the Runtime menu to:\n",
        "* set up the network and load our trained model,\n",
        "* apply it to an RGB input to generate a 32-layer MPI,\n",
        "* show individual MPI layers and synthesized disparity,\n",
        "* render novel views from different camera positions,\n",
        "* visualize the resulting MPI in an HTML-based viewer.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpDKjdWWk7zi"
      },
      "source": [
        "## Download library code, model weights, and example image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKire3Obk2ra",
        "outputId": "5d711a03-125d-4dda-eb08-58d31f02e67c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching code from github...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "subversion is already the newest version (1.9.7-4ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "A    single_view_mpi\n",
            "A    single_view_mpi/README.md\n",
            "A    single_view_mpi/example.ipynb\n",
            "A    single_view_mpi/libs\n",
            "A    single_view_mpi/libs/geometry.py\n",
            "A    single_view_mpi/libs/geometry_test.py\n",
            "A    single_view_mpi/libs/mpi.py\n",
            "A    single_view_mpi/libs/mpi_test.py\n",
            "A    single_view_mpi/libs/nets.py\n",
            "A    single_view_mpi/libs/utils.py\n",
            "A    single_view_mpi/libs/utils_test.py\n",
            "A    single_view_mpi/requirements.txt\n",
            "A    single_view_mpi/run.sh\n",
            "Exported revision 9726.\n",
            "\n",
            "Fetching trained model weights...\n",
            "--2022-03-19 01:45:01--  https://storage.googleapis.com/stereo-magnification-public-files/models/single_view_mpi_full_keras.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.189.128, 108.177.125.128, 142.250.157.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.189.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 161684857 (154M) [application/x-gzip]\n",
            "Saving to: ‘single_view_mpi_full_keras.tar.gz’\n",
            "\n",
            "single_view_mpi_ful 100%[===================>] 154.19M  97.9MB/s    in 1.6s    \n",
            "\n",
            "2022-03-19 01:45:02 (97.9 MB/s) - ‘single_view_mpi_full_keras.tar.gz’ saved [161684857/161684857]\n",
            "\n",
            "single_view_mpi_full_keras/\n",
            "single_view_mpi_full_keras/._checkpoint\n",
            "single_view_mpi_full_keras/checkpoint\n",
            "single_view_mpi_full_keras/._single_view_mpi_keras_weights.index\n",
            "single_view_mpi_full_keras/single_view_mpi_keras_weights.index\n",
            "single_view_mpi_full_keras/._single_view_mpi_keras_weights.data-00000-of-00001\n",
            "single_view_mpi_full_keras/single_view_mpi_keras_weights.data-00000-of-00001\n",
            "\n",
            "Fetching example image...\n",
            "--2022-03-19 01:45:06--  https://single-view-mpi.github.io/mpi/7/input.png\n",
            "Resolving single-view-mpi.github.io (single-view-mpi.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to single-view-mpi.github.io (single-view-mpi.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 350399 (342K) [image/png]\n",
            "Saving to: ‘input.png’\n",
            "\n",
            "input.png           100%[===================>] 342.19K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2022-03-19 01:45:06 (8.16 MB/s) - ‘input.png’ saved [350399/350399]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!echo Fetching code from github...\n",
        "!apt install subversion\n",
        "!svn export --force https://github.com/google-research/google-research/trunk/single_view_mpi\n",
        "\n",
        "!echo\n",
        "!echo Fetching trained model weights...\n",
        "!rm single_view_mpi_full_keras.tar.gz\n",
        "!rm -rf single_view_mpi_full\n",
        "!wget https://storage.googleapis.com/stereo-magnification-public-files/models/single_view_mpi_full_keras.tar.gz\n",
        "!tar -xzvf single_view_mpi_full_keras.tar.gz\n",
        "\n",
        "!echo\n",
        "!echo Fetching example image...\n",
        "!rm -f input.png\n",
        "!wget https://single-view-mpi.github.io/mpi/7/input.png\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLxv0DvYqGhy"
      },
      "source": [
        "## Set up the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saA4-roFkvsA",
        "outputId": "b66cbb12-1cb9-4f44-8fb9-0635ff5a3743"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.2.0 in /usr/local/lib/python3.7/dist-packages (from -r single_view_mpi/requirements.txt (line 1)) (2.2.0)\n",
            "Requirement already satisfied: tensorflow-addons==0.10.0 in /usr/local/lib/python3.7/dist-packages (from -r single_view_mpi/requirements.txt (line 2)) (0.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (0.37.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (2.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (2.2.2)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (2.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (1.1.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (1.44.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (1.13.3)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (0.3.3)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (1.21.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (3.17.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons==0.10.0->-r single_view_mpi/requirements.txt (line 2)) (2.7.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (3.3.6)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (57.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (3.10.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r single_view_mpi/requirements.txt (line 1)) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "pip install -r single_view_mpi/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlX8AfkNzHfR",
        "outputId": "e54fb56c-b857-4ad3-aa55-4970968b60e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model created.\n",
            "Weights loaded.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from single_view_mpi.libs import mpi\n",
        "from single_view_mpi.libs import nets\n",
        "\n",
        "input = tf.keras.Input(shape=(None, None, 3))\n",
        "output = nets.mpi_from_image(input)\n",
        "\n",
        "model = tf.keras.Model(inputs=input, outputs=output)\n",
        "print('Model created.')\n",
        "# Our full model, trained on RealEstate10K.\n",
        "model.load_weights('single_view_mpi_full_keras/single_view_mpi_keras_weights')\n",
        "print('Weights loaded.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the samples of data we want to analyze"
      ],
      "metadata": {
        "id": "1EKwkCCIrk6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "FILE_PATH = \"gdrive/MyDrive/cs 231a/realestate10k/\"\n",
        "os.chdir(FILE_PATH)"
      ],
      "metadata": {
        "id": "Gttp7bK7rocE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paintings = os.listdir()\n",
        "paintings[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "1LkEIvVwscpb",
        "outputId": "0ea1ba21-d004-4745-bdf8-0afd0223fae8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'40173467.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(paintings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da9fCIzUse4F",
        "outputId": "1d8023dc-7984-4322-8323-21fe7b330646"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "295"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "sample_sz = 100\n",
        "random_sample = random.sample(paintings, sample_sz)\n",
        "random_sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX-NKIs6shJ0",
        "outputId": "2ad8700e-cde6-46fd-ff28-37a6f86d663a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['51151100.jpg',\n",
              " '40073367.jpg',\n",
              " '55121000.jpg',\n",
              " '39205833.jpg',\n",
              " '57624000.jpg',\n",
              " '50950900.jpg',\n",
              " '40140100.jpg',\n",
              " '59960000.jpg',\n",
              " '55155000.jpg',\n",
              " '50717333.jpg',\n",
              " '59259000.jpg',\n",
              " '55889000.jpg',\n",
              " '58158000.jpg',\n",
              " '50683967.jpg',\n",
              " '56356000.jpg',\n",
              " '38905533.jpg',\n",
              " '56223000.jpg',\n",
              " '41107733.jpg',\n",
              " '55722000.jpg',\n",
              " '41007633.jpg',\n",
              " '50417033.jpg',\n",
              " '50550500.jpg',\n",
              " '55422000.jpg',\n",
              " '39239200.jpg',\n",
              " '54854000.jpg',\n",
              " '54221000.jpg',\n",
              " '58592000.jpg',\n",
              " '57724000.jpg',\n",
              " '59660000.jpg',\n",
              " '39739700.jpg',\n",
              " '58292000.jpg',\n",
              " '39172467.jpg',\n",
              " '50250200.jpg',\n",
              " '59126000.jpg',\n",
              " '56657000.jpg',\n",
              " '58725000.jpg',\n",
              " '57691000.jpg',\n",
              " '57557000.jpg',\n",
              " '55222000.jpg',\n",
              " '56590000.jpg',\n",
              " '58025000.jpg',\n",
              " '39973267.jpg',\n",
              " '57824000.jpg',\n",
              " '57924000.jpg',\n",
              " '59159000.jpg',\n",
              " '38872167.jpg',\n",
              " '40573867.jpg',\n",
              " '41474767.jpg',\n",
              " '38972267.jpg',\n",
              " '40006633.jpg',\n",
              " '39773067.jpg',\n",
              " '39072367.jpg',\n",
              " '56390000.jpg',\n",
              " '58859000.jpg',\n",
              " '59192000.jpg',\n",
              " '54421000.jpg',\n",
              " '39706333.jpg',\n",
              " '56423000.jpg',\n",
              " '51251200.jpg',\n",
              " '41241200.jpg',\n",
              " '40106733.jpg',\n",
              " '56056000.jpg',\n",
              " '39339300.jpg',\n",
              " '56556000.jpg',\n",
              " '39539500.jpg',\n",
              " '39873167.jpg',\n",
              " '57791000.jpg',\n",
              " '54754000.jpg',\n",
              " '40173467.jpg',\n",
              " '54955000.jpg',\n",
              " '40807433.jpg',\n",
              " '55255000.jpg',\n",
              " '50150100.jpg',\n",
              " '59293000.jpg',\n",
              " '58191000.jpg',\n",
              " '40707333.jpg',\n",
              " '59426000.jpg',\n",
              " '59393000.jpg',\n",
              " '38805433.jpg',\n",
              " '40507133.jpg',\n",
              " '38938900.jpg',\n",
              " '57658000.jpg',\n",
              " '54621000.jpg',\n",
              " '40306933.jpg',\n",
              " '55021000.jpg',\n",
              " '50283567.jpg',\n",
              " '40774067.jpg',\n",
              " '50016633.jpg',\n",
              " '56089000.jpg',\n",
              " '55522000.jpg',\n",
              " '58558000.jpg',\n",
              " '54988000.jpg',\n",
              " '59893000.jpg',\n",
              " '58492000.jpg',\n",
              " '39672967.jpg',\n",
              " '55655000.jpg',\n",
              " '40940900.jpg',\n",
              " '56256000.jpg',\n",
              " '41408033.jpg',\n",
              " '41374667.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate PSNR and SSIM\n",
        "\n",
        "Sourced from: https://cvnote.ddlee.cc/2019/09/12/psnr-ssim-python"
      ],
      "metadata": {
        "id": "BkfEqFT2nb83"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "h1xuQHy7Ggw2"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "def calculate_psnr(img1, img2):\n",
        "    # img1 and img2 have range [0, 255]\n",
        "    # img1 = img1.astype(np.float64)\n",
        "    # img2 = img2.astype(np.float64)\n",
        "    mse = np.mean((img1 - img2)**2)\n",
        "    if mse == 0:\n",
        "        return float('inf')\n",
        "    return 20 * math.log10(255.0 / math.sqrt(mse))\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def ssim(img1, img2):\n",
        "    C1 = (0.01 * 255)**2\n",
        "    C2 = (0.03 * 255)**2\n",
        "\n",
        "    # img1 = img1.astype(np.float64)\n",
        "    # img2 = img2.astype(np.float64)\n",
        "    kernel = cv2.getGaussianKernel(11, 1.5)\n",
        "    window = np.outer(kernel, kernel.transpose())\n",
        "\n",
        "    mu1 = cv2.filter2D(img1, -1, window)[5:-5, 5:-5]  # valid\n",
        "    mu2 = cv2.filter2D(img2, -1, window)[5:-5, 5:-5]\n",
        "    mu1_sq = mu1**2\n",
        "    mu2_sq = mu2**2\n",
        "    mu1_mu2 = mu1 * mu2\n",
        "    sigma1_sq = cv2.filter2D(img1**2, -1, window)[5:-5, 5:-5] - mu1_sq\n",
        "    sigma2_sq = cv2.filter2D(img2**2, -1, window)[5:-5, 5:-5] - mu2_sq\n",
        "    sigma12 = cv2.filter2D(img1 * img2, -1, window)[5:-5, 5:-5] - mu1_mu2\n",
        "\n",
        "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) *\n",
        "                                                            (sigma1_sq + sigma2_sq + C2))\n",
        "    return ssim_map.mean()\n",
        "\n",
        "\n",
        "def calculate_ssim(img1, img2):\n",
        "    '''calculate SSIM\n",
        "    the same outputs as MATLAB's\n",
        "    img1, img2: [0, 255]\n",
        "    '''\n",
        "    if not img1.shape == img2.shape:\n",
        "        raise ValueError('Input images must have the same dimensions.')\n",
        "    if img1.ndim == 2:\n",
        "        return ssim(img1, img2)\n",
        "    elif img1.ndim == 3:\n",
        "        if img1.shape[2] == 3:\n",
        "            ssims = []\n",
        "            for i in range(3):\n",
        "                ssims.append(ssim(img1, img2))\n",
        "            return np.array(ssims).mean()\n",
        "        elif img1.shape[2] == 1:\n",
        "            return ssim(np.squeeze(img1), np.squeeze(img2))\n",
        "    else:\n",
        "        raise ValueError('Wrong input image dimensions.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputfile = random_sample[0]\n",
        "input_rgb = tf.image.decode_image(tf.io.read_file(inputfile), dtype=tf.float32)\n",
        "\n",
        "# Generate MPI\n",
        "# image: (1, 1024, 1024, 3)\n",
        "print(input_rgb.shape)\n",
        "N, H, W, C = input_rgb[tf.newaxis].shape\n",
        "# enforce square representation\n",
        "arr = np.zeros((1, 1024 - H, W, C))\n",
        "representation = np.append(input_rgb[tf.newaxis], arr, axis=1)\n",
        "print(representation.shape)\n",
        "representation = representation[0:1, 0:1024, 0: 1024, 0:3]\n",
        "print(representation.shape)\n",
        "print(input_rgb[tf.newaxis].shape)\n",
        "layers = model(representation)[0]\n",
        "print(layers[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kL13ACPrwLdk",
        "outputId": "a91e685a-e5b3-45a5-eca6-720a54347f5a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(720, 1280, 3)\n",
            "(1, 1024, 1280, 3)\n",
            "(1, 1024, 1024, 3)\n",
            "(1, 720, 1280, 3)\n",
            "(1024, 1024, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate SSIM and PSNR for samples\n",
        "num_layers = 32\n",
        "# ssims = np.zeros((sample_sz, num_layers))\n",
        "# psnrs = np.zeros((sample_sz, num_layers))\n",
        "ssims = np.zeros(sample_sz)\n",
        "psnrs = np.zeros(sample_sz)\n",
        "for i in range(sample_sz):\n",
        "  if (i % 10 == 0):\n",
        "    print(i)\n",
        "  # Input image\n",
        "  inputfile = random_sample[i]\n",
        "  input_rgb = tf.image.decode_image(tf.io.read_file(inputfile), dtype=tf.float32)\n",
        "\n",
        "  # Generate MPI\n",
        "  # print(input_rgb.shape)\n",
        "  N, H, W, C = input_rgb[tf.newaxis].shape\n",
        "  # enforce square representation for 1024 x 1024 images\n",
        "  arr = np.zeros((1, 1024 - H, W, C))\n",
        "  representation = np.append(input_rgb[tf.newaxis], arr, axis=1)\n",
        "  representation = representation[0:1, 0:1024, 0: 1024, 0:3]\n",
        "  layers = model(representation)[0]\n",
        "\n",
        "  # Note: this only selects RGB layers and not output\n",
        " \n",
        "  # for j in range(len(layers)):\n",
        "    # ssims[i][j] = calculate_ssim(input_rgb.numpy(), layers[j][:, :, 0:3].numpy())\n",
        "    # psnrs[i][j] = calculate_psnr(input_rgb, layers[j][:, :, 0:3])\n",
        "    # calculate for the first layer\n",
        "  ssims[i] = calculate_ssim(representation.reshape((1024, 1024, 3)), layers[0][:, :, 0:3].numpy())\n",
        "  psnrs[i] = calculate_psnr(representation.reshape((1024, 1024, 3)), layers[0][:, :, 0:3])\n",
        "\n",
        "print(\"mean ssim:\")\n",
        "print(ssims.mean())\n",
        "print(\"mean psnr:\")\n",
        "print(psnrs.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJ3wMY_ItKT4",
        "outputId": "1190ff0a-7b0d-4d1b-d108-c5d7b11dd2f5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "70\n",
            "80\n",
            "90\n",
            "mean ssim:\n",
            "0.999903337703274\n",
            "mean psnr:\n",
            "77.83639952305774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mDeEATz_5-bh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "SSIM and PSNR single-view-mpi_realestate10K.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}